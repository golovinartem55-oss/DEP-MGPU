Цель работы:
Научиться создавать, настраивать и запускать простой Airflow DAG для выполнения команд проекта dbt (data build tool), который преобразует данные. Работа может быть выполнена как в облачной среде Google Cloud Platform, так и локально с использованием Docker.
Вариант 11. Анализ клиентской базы B2B
Было выбрано Локальное решение (Docker) в виду быстрой настройки и отладки; соответствию компьютера техническим требованиям; ранее уже приходилось работать через Docker
Все файлы представлены в папке project, дерево проекта:
![Screenshot_1](https://github.com/user-attachments/assets/3356981f-74e3-475c-b15f-e3bbf0faea18)
В postresql данные также были загружены:
<img width="1036" height="606" alt="image" src="https://github.com/user-attachments/assets/0ca8e752-e00f-4e57-a4cf-139fbe96b685" />
Файл dbt_project.yml:
<img width="723" height="401" alt="image" src="https://github.com/user-attachments/assets/ef620e9d-ff7a-489b-99cf-2eaffe2e6a4e" />
Файл с дагом:
<img width="597" height="358" alt="image" src="https://github.com/user-attachments/assets/226b5baf-197c-4d66-a009-619484892952" />
Вывод:
В ходе выполнения практической работы были изучены ключевые аспекты построения современных ELT-процессов с использованием связки Apache Airflow и dbt (инструмент для сборки данных). Был реализован полный цикл обработки данных: от загрузки исходной клиентской базы B2B до построения аналитических показателей — среднего размера контракта, продолжительности сотрудничества и доли рынка.

Преимущества связки Airflow + dbt:
1. Airflow обеспечивает надёжную оркестрацию: управление зависимостями, повторный запуск в случае сбоя, визуальный мониторинг и планирование.
2. dbt позволяет писать трансформации на чистом SQL с поддержкой модульности, документирования, тестирования и управления зависимостями между моделями.




